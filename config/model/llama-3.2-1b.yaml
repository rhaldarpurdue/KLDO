defaults:
  - base_model

name_or_path: meta-llama/Llama-3.2-1B
block_name: LlamaDecoderLayer
attn_implementation: flash_attention_2